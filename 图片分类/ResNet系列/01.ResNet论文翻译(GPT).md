## Deep Residual Learning for Image Recognition（用于图像识别的深度残差学习）
https://arxiv.org/abs/1512.03385

### Abstract
&emsp;深度神经网络训练更加困难。我们提出了一个残差学习框架，用于缓解比以前更深的网络的训练难度。**我们明确地将层重新表述为与层输入相关的学习残差函数，而不是学习无关的函数。我们提供了全面的实证证据表明这些残差网络更容易优化，并且可以从显著增加的深度中获得准确性提升**。在ImageNet数据集上，我们评估具有高达152层深度的残差网络，比VGG网络[41]深8倍，但复杂度仍然较低。这些残差网络的集合在ImageNet测试集上实现了3.57％的误差。这个结果赢得了ILSVRC 2015分类任务的第一名。我们还对具有100和1000层的CIFAR-10进行了分析。  
&emsp;对于许多视觉识别任务来说，表示的深度至关重要。仅仅由于我们极其深的表示方式，在COCO对象检测数据集上取得了28％的相对改进。深度残差网络是我们提交到ILSVRC＆COCO 2015竞赛的基础，我们还在ImageNet检测，ImageNet本地化，COCO检测和COCO分割等任务上获得了第一名。  

### Introduction
&emsp;深度卷积神经网络[22, 21]为图像分类[21, 50, 40]带来了一系列突破。深层网络自然地以[端到端](https://github.com/CloseYYLab/YiliYili/blob/main/%E9%80%9A%E7%94%A8%E7%9F%A5%E8%AF%86%E7%82%B9.md#%E7%AB%AF%E5%88%B0%E7%AB%AF)的多层方式整合了低/中/高级特征[50]和分类器，并且特征的“层级”可以通过堆叠的层数（深度）来增强。最近的证据[41, 44]表明，网络的深度至关重要，在具有挑战性的ImageNet数据集[36]上，所有领先的结果[41, 44, 13, 16]都利用了“非常深”的[41]模型，深度为十六[41]到三十[16]层。许多其他复杂的视觉识别任务[8, 12, 7, 32, 27]也极大地受益于非常深的模型。  
&emsp;由于深度的重要性，一个问题出现了：学习更好的网络是否就像简单地堆叠更多的层那样容易？回答这个问题的障碍是臭名昭著的[梯度消失/爆炸](https://github.com/CloseYYLab/YiliYili/blob/main/%E9%80%9A%E7%94%A8%E7%9F%A5%E8%AF%86%E7%82%B9.md#%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8)问题[1, 9]，它从一开始就阻碍了收敛。然而，通过归一化初始化[23, 9, 37, 13]和中间归一化层[16]，这个问题在很大程度上得到了解决，它使得具有数十层的网络可以开始收敛于带有反向传播的随机梯度下降（SGD）[22]。  
&emsp;当更深的网络能够开始收敛时，出现了一个退化问题：随着网络深度的增加，准确性达到饱和（这可能是不足为奇的），然后迅速下降。令人意外的是，这种退化不是由过拟合引起的，在[11, 42]中报告，并经过我们的实验证实，将更多的层添加到适当深度的模型中会导致更高的训练误差。图1展示了一个典型的例子。  
![image](https://github.com/CloseYYLab/YiliYili/assets/56760687/66a27cdc-4a94-4eea-9e6b-4492e5312e6d)
&emsp;Figure 1.左图是在CIFAR-10数据集上使用20层和56层“plain”网络的训练误差，右图是测试误差。较深的网络具有较高的训练误差，因此也具有较高的测试误差。类似的现象在图4中展示了在ImageNet数据集上的情况。  
&emsp;训练准确率的下降表明，并非所有系统都容易优化。我们考虑一个较浅的架构和加入更多层的较深架构。存在这样一种解决方案：通过构造，深层模型中添加的层是恒等映射，其他层则从学习得到的较浅模型中复制而来。这种构造解的存在表明，深层模型的训练误差不应高于其相对较浅的对应模型。但实验结果表明，目前手头可用的求解器无法找到与构造解同等或更好的解（或无法在合理的时间内找到解）。  
&emsp;本文通过引入深度残差学习框架来解决退化问题。我们不再期望每几个堆叠的层能够直接拟合所需的底层映射，而是明确地让这些层拟合后面的残差映射。具体地，将所需的底层映射表示为H（x），我们让堆叠的非线性层拟合另一个映射F（x）：= H（x）- x。原始映射被重新表示为F（x）+ x。我们假设，优化残差映射比优化原始未参考的映射更容易。极端地，如果恒等映射是最优的，则将残差推向零比通过堆叠非线性层拟合恒等映射更容易。  
&emsp;公式 F(x) + x 可以通过使用“shortcut connections”（图2）的前馈神经网络来实现。“Shortcut connections”（2、34、49）是指跳过一个或多个层的连接。在我们的情况下，这些“shortcut connections”仅执行恒等映射，它们的输出被加到堆叠层的输出中（图2）。恒等“shortcut connections”既不增加额外的参数也不增加计算复杂度。整个网络仍然可以通过采用 SGD 反向传播的端对端训练，并且可以使用常见的库（例如 Caffe [19]）轻松实现，而无需修改求解器。  
&emsp;我们在ImageNet [36]上进行了全面的实验，以展示退化问题并评估我们的方法。我们展示了以下结果：1）我们极深的残差网络易于优化，而对应的“普通”网络（只是简单堆叠层）在深度增加时训练误差更高；2）我们的深度残差网络可以从大幅增加的深度中轻松获得准确性提升，产生比之前的网络更好的结果。  
&emsp;类似的现象也在CIFAR-10数据集[20]上得到了展示，这表明优化困难和我们方法的效果不仅适用于特定的数据集。我们成功地在该数据集上训练了超过100层的模型，并探索了超过1000层的模型。  
&emsp;在ImageNet分类数据集[36]上，我们通过极深的残差网络获得了出色的结果。我们的152层残差网络是迄今为止在ImageNet上展示的最深网络，但其复杂性仍低于VGG网络[41]。我们的集成模型在ImageNet测试集上的top-5误差率为3.57%，并在ILSVRC 2015分类竞赛中获得了第一名。这种极深表示在其他识别任务上也具有出色的泛化性能，并使我们在ILSVRC＆COCO 2015竞赛中进一步获得了ImageNet检测、ImageNet定位、COCO检测和COCO分割等方面的第一名。这些强有力的证据表明残差学习原理是通用的，并且我们希望它在其他视觉和非视觉问题中也适用。  
