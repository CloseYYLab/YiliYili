## Deep Residual Learning for Image Recognition（用于图像识别的深度残差学习）
https://arxiv.org/abs/1512.03385

### Abstract
&emsp;深度神经网络训练更加困难。我们提出了一个残差学习框架，用于缓解比以前更深的网络的训练难度。**我们明确地将层重新表述为与层输入相关的学习残差函数，而不是学习无关的函数。我们提供了全面的实证证据表明这些残差网络更容易优化，并且可以从显著增加的深度中获得准确性提升**。在ImageNet数据集上，我们评估具有高达152层深度的残差网络，比VGG网络[41]深8倍，但复杂度仍然较低。这些残差网络的集合在ImageNet测试集上实现了3.57％的误差。这个结果赢得了ILSVRC 2015分类任务的第一名。我们还对具有100和1000层的CIFAR-10进行了分析。  
&emsp;对于许多视觉识别任务来说，表示的深度至关重要。仅仅由于我们极其深的表示方式，在COCO对象检测数据集上取得了28％的相对改进。深度残差网络是我们提交到ILSVRC＆COCO 2015竞赛的基础，我们还在ImageNet检测，ImageNet本地化，COCO检测和COCO分割等任务上获得了第一名。  

### Introduction
&emsp;深度卷积神经网络[22, 21]为图像分类[21, 50, 40]带来了一系列突破。深层网络自然地以[端到端](https://github.com/CloseYYLab/YiliYili/blob/main/%E9%80%9A%E7%94%A8%E7%9F%A5%E8%AF%86%E7%82%B9.md#%E7%AB%AF%E5%88%B0%E7%AB%AF)的多层方式整合了低/中/高级特征[50]和分类器，并且特征的“层级”可以通过堆叠的层数（深度）来增强。最近的证据[41, 44]表明，网络的深度至关重要，在具有挑战性的ImageNet数据集[36]上，所有领先的结果[41, 44, 13, 16]都利用了“非常深”的[41]模型，深度为十六[41]到三十[16]层。许多其他复杂的视觉识别任务[8, 12, 7, 32, 27]也极大地受益于非常深的模型。  
&emsp;由于深度的重要性，一个问题出现了：学习更好的网络是否就像简单地堆叠更多的层那样容易？回答这个问题的障碍是臭名昭著的梯度消失/爆炸问题[1, 9]，它从一开始就阻碍了收敛。然而，通过归一化初始化[23, 9, 37, 13]和中间归一化层[16]，这个问题在很大程度上得到了解决，它使得具有数十层的网络可以开始收敛于带有反向传播的随机梯度下降（SGD）[22]。  
&emsp;当更深的网络能够开始收敛时，出现了一个退化问题：随着网络深度的增加，准确性达到饱和（这可能是不足为奇的），然后迅速下降。令人意外的是，这种退化不是由过拟合引起的，在[11, 42]中报告，并经过我们的实验证实，将更多的层添加到适当深度的模型中会导致更高的训练误差。图1展示了一个典型的例子。  
![image](https://github.com/CloseYYLab/YiliYili/assets/56760687/66a27cdc-4a94-4eea-9e6b-4492e5312e6d)
&emsp;Figure 1.左图是在CIFAR-10数据集上使用20层和56层“plain”网络的训练误差，右图是测试误差。较深的网络具有较高的训练误差，因此也具有较高的测试误差。类似的现象在图4中展示了在ImageNet数据集上的情况。  
&emsp;训练准确率的下降表明，并非所有系统都容易优化。我们考虑一个较浅的架构和加入更多层的较深架构。存在这样一种解决方案：通过构造，深层模型中添加的层是恒等映射，其他层则从学习得到的较浅模型中复制而来。这种构造解的存在表明，深层模型的训练误差不应高于其相对较浅的对应模型。但实验结果表明，目前手头可用的求解器无法找到与构造解同等或更好的解（或无法在合理的时间内找到解）。  
&emsp;本文通过引入深度残差学习框架来解决退化问题。我们不再期望每几个堆叠的层能够直接拟合所需的底层映射，而是明确地让这些层拟合后面的残差映射。具体地，将所需的底层映射表示为H（x），我们让堆叠的非线性层拟合另一个映射F（x）：= H（x）- x。原始映射被重新表示为F（x）+ x。我们假设，优化残差映射比优化原始未参考的映射更容易。极端地，如果恒等映射是最优的，则将残差推向零比通过堆叠非线性层拟合恒等映射更容易。  
